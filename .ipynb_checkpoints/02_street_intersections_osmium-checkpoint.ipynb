{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72db9b67-ef52-4e73-9b46-b833c1e84def",
   "metadata": {},
   "source": [
    "This notebook contains code on collecting street intersection data from OSM for the generated grids and then calculating the number of street intersections (edges>=3) for each 100m x 100m grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be96cfb-9672-48db-91a5-b28c389ea92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from multiprocess import Pool\n",
    "import gc\n",
    "import osmium\n",
    "import shapely.geometry\n",
    "from shapely.geometry import box\n",
    "import subprocess\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6875865-2449-41a8-bf59-4f20eeb6c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for grid files\n",
    "# you might have grids generated here from the 'generate_grids.ipynb'\n",
    "grid_path = 'data/*.parquet'\n",
    "\n",
    "# create a list of all parquet grid files from the specified directory\n",
    "grids_list = [parquet for parquet in glob.glob(grid_path)]\n",
    "print(grids_list)\n",
    "\n",
    "# # configure logging (recommended if you monitor processing over a lot of files)\n",
    "# log_path = 'logs/street_intersections.log'\n",
    "\n",
    "# # ensure log directory exists\n",
    "# log_dir = os.path.dirname(log_path)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "    \n",
    "# logging.basicConfig(filename=log_path, level=logging.INFO,\n",
    "#                     format='%(asctime)s:%(levelname)s:%(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f50967-5ddd-41e0-9e7a-0bb382a135be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_walkable(tags):\n",
    "    excluded_highways = {\n",
    "        \"abandoned\", \"bus_guideway\", \"construction\", \"cycleway\", \"motor\",\n",
    "        \"no\", \"planned\", \"platform\", \"proposed\", \"raceway\", \"razed\", \"service\"\n",
    "    }\n",
    "    hwy = tags.get(\"highway\")\n",
    "    if not hwy or hwy in excluded_highways:\n",
    "        return False\n",
    "    if tags.get(\"foot\") == \"no\":\n",
    "        return False\n",
    "    if tags.get(\"access\") == \"private\":\n",
    "        return False\n",
    "    if tags.get(\"area\") == \"yes\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def extract_graph_edges(pbf_path):\n",
    "    node_locations = {}\n",
    "    edges = []\n",
    "\n",
    "    class Handler(osmium.SimpleHandler):\n",
    "        def node(self, n):\n",
    "            if n.location.valid():\n",
    "                node_locations[n.id] = (n.location.lon, n.location.lat)\n",
    "\n",
    "        def way(self, w):\n",
    "            if is_walkable(w.tags):\n",
    "                node_refs = [n.ref for n in w.nodes]\n",
    "                # add edges between consecutive node pairs\n",
    "                for u, v in zip(node_refs[:-1], node_refs[1:]):\n",
    "                    edges.append((u, v))\n",
    "\n",
    "    handler = Handler()\n",
    "    handler.apply_file(pbf_path, locations=True)\n",
    "    return edges, node_locations\n",
    "\n",
    "\n",
    "def build_graph(edges, node_locations):\n",
    "    G = nx.Graph()\n",
    "    for u, v in edges:\n",
    "        if u in node_locations and v in node_locations:\n",
    "            G.add_edge(u, v)\n",
    "    return G\n",
    "\n",
    "\n",
    "def count_streets(G, min_street_count=3):\n",
    "    intersections = {\n",
    "        node: G.degree(node)\n",
    "        for node in G.nodes\n",
    "        if G.degree(node) >= min_street_count\n",
    "    }\n",
    "    return intersections\n",
    "\n",
    "\n",
    "def intersections_to_gdf(intersections, node_locations):\n",
    "    ids = list(intersections.keys())\n",
    "    coords = [shapely.geometry.Point(*node_locations[nid]) for nid in ids]\n",
    "    gdf = gpd.GeoDataFrame({'id': ids, 'street_count': list(intersections.values())}, \n",
    "                           geometry=coords, crs=\"EPSG:4326\")\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def extract_intersections_from_pbf(pbf_path, min_street_count=3):\n",
    "    edges, node_locations = extract_graph_edges(pbf_path)\n",
    "    G = build_graph(edges, node_locations)\n",
    "    intersections = count_streets(G, min_street_count)\n",
    "    return intersections_to_gdf(intersections, node_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6db2ec-6d3c-42c2-ba59-c0f0d3b22323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_grid(grid_path):\n",
    "    \"\"\"\n",
    "    Processes each grid to count street intersections within it.\n",
    "    \n",
    "    Args:\n",
    "    - grid_path (str): Path to the grid file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grid_number = grid_path.split('_')[-1].split('.')[0]\n",
    "\n",
    "        grid_gdf = gpd.read_parquet(grid_path)\n",
    "        output_dir = os.path.join(os.path.dirname(grid_path), 'street_intersection_data')\n",
    "        output_file = f'street_intersections_{grid_number}.parquet'\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(os.path.join(output_dir, output_file)):\n",
    "            logging.info(f'Skipping {output_file} as it already exists')\n",
    "            print(f'Skipping {output_file} as it already exists')\n",
    "            return\n",
    "\n",
    "        if 'index' not in grid_gdf.columns:\n",
    "            grid_gdf.reset_index(inplace=True)\n",
    "\n",
    "        if 'num_street_intersections' in grid_gdf.columns:\n",
    "            grid_gdf.drop(columns=['num_street_intersections'], inplace=True)\n",
    "\n",
    "        grid_gdf_4326 = grid_gdf.to_crs('epsg:4326')\n",
    "        bounds = grid_gdf_4326.total_bounds\n",
    "        buffered_box = box(*bounds).buffer(0.01)  # ~1 km buffer in degrees\n",
    "        # logging.info(f'Started processing grid {grid_number}')\n",
    "        print(f'Started processing grid {grid_number}')\n",
    "\n",
    "        # clip .pbf file\n",
    "        clipped_pbf_path = f'data/{grid_number}.pbf'\n",
    "        os.makedirs(os.path.dirname(clipped_pbf_path), exist_ok=True)\n",
    "\n",
    "        bbox_str = ','.join(map(str, buffered_box.bounds))\n",
    "        subprocess.run([\n",
    "            'osmium', 'extract',\n",
    "            '-b', bbox_str,\n",
    "            '/Volumes/ssd1/osm_europe/europe-latest.osm.pbf',\n",
    "            '-o', clipped_pbf_path,\n",
    "            '--overwrite'\n",
    "        ], check=True)\n",
    "        print(f'clipped PBF for {grid_number}')\n",
    "        \n",
    "        # process with pyosmium\n",
    "        gdf_nodes = extract_intersections_from_pbf(clipped_pbf_path)\n",
    "        gdf_nodes.to_crs(grid_gdf.crs, inplace=True)\n",
    "        \n",
    "        gdf_nodes.to_parquet(os.path.join(output_dir, output_file))\n",
    "        # logging.info(f'Saved intersection data to {output_file}')\n",
    "        print(f'Saved intersection data to {output_file}')\n",
    "\n",
    "        joined = gpd.sjoin(grid_gdf, gdf_nodes, how='left', predicate='intersects')\n",
    "        node_counts_per_grid = joined.groupby('index')['index_right'].nunique().reset_index(name='num_street_intersections')\n",
    "        grid_gdf_f = grid_gdf.merge(node_counts_per_grid, on='index', how='left').fillna({'num_street_intersections': 0})\n",
    "        grid_gdf_f.to_parquet(grid_path)\n",
    "        \n",
    "        # logging.info(f'Successfully processed grid {grid_path}')\n",
    "        print(f'Successfully processed grid {grid_path}')\n",
    "\n",
    "        # clean up temp PBF file\n",
    "        if os.path.exists(clipped_pbf_path):\n",
    "            os.remove(clipped_pbf_path)\n",
    "            \n",
    "        del gdf_nodes, grid_gdf, grid_gdf_f\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        # logging.error(f'Error processing grid {grid_path}: {e}')\n",
    "        print(f'Error processing grid {grid_path}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a56828-d9d3-4491-a0bf-d7ff912bbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "for elem in grids_list:\n",
    "    process_grid(elem)\n",
    "\n",
    "# # parallel processsing if you want to process a lot of files\n",
    "# num_processes = 5\n",
    "\n",
    "# with Pool(processes=num_processes) as pool:\n",
    "#     pool.map(process_grid, grids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e85ad-c7fc-40dc-9037-c92e66abb202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
