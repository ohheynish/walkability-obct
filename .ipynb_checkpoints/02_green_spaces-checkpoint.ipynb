{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577b0eae-aedc-4eb1-a793-8bae63b6db67",
   "metadata": {},
   "source": [
    "This notebook contains code on collecting green spaces (approximated as NDVI) from Sentinel-2 for the generated grids and then calculating the NDVI value for each 100m x 100m grid. The developed code relies on google earth engine for processing and google cloud for intermediate storage of data. One can look into STAC APIs for alternate way of processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1fd432-fff7-419e-bc06-b3c118b1d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from multiprocess import Pool\n",
    "import glob\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951d949-f414-4269-8367-187797288cc0",
   "metadata": {},
   "source": [
    "### data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6e56f-d160-420c-adbe-2107c56d29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to mask clouds in Sentinel-2 images using the Scene Classification Layer (SCL)\n",
    "def maskS2CloudsUsingSCL(image):\n",
    "    scl = image.select('SCL')\n",
    "    cloud_mask = scl.gt(6).Or(scl.lt(4))  # Clouds are typically classified as values <4 or >6\n",
    "    return image.updateMask(cloud_mask.Not()).divide(10000)  # Apply mask and scale reflectance\n",
    "\n",
    "# function to add an NDVI band to a Sentinel-2 image\n",
    "def addNDVI(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')  # B8 (NIR) and B4 (Red)\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "# function to calculate the first quartile of an image collection\n",
    "def firstQuartile(imageCollection):\n",
    "    return imageCollection.reduce(ee.Reducer.percentile([25]))  # Compute the 25th percentile\n",
    "\n",
    "# convert a Shapely Polygon to an Earth Engine Geometry Polygon\n",
    "def shapely_to_ee_polygon(shapely_geom):\n",
    "    exterior_coords = list(shapely_geom.exterior.coords)\n",
    "    return ee.Geometry.Polygon(exterior_coords)\n",
    "\n",
    "# function to manage Earth Engine task submission, ensuring task queue does not overflow\n",
    "def wait_for_slots(max_tasks=2000, check_interval=60):\n",
    "    while True:\n",
    "        tasks = ee.data.getTaskList()\n",
    "        running_or_ready_tasks = [task for task in tasks if task['state'] in ('RUNNING', 'READY')]\n",
    "        if len(running_or_ready_tasks) < max_tasks:\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Queue full with {len(running_or_ready_tasks)} tasks. Waiting...\")\n",
    "            time.sleep(check_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35252b-0dd3-4349-be12-ee5aa138867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate and initialize the Earth Engine session\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# load and reproject the 100km x 100km grid\n",
    "eu_gdf = gpd.read_file('data/grid_100km_surf.gpkg')\n",
    "eu_4326 = eu_gdf.to_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f0940-9148-4119-856a-6f4740bd2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process each row in the reprojected geodataframe\n",
    "for i, row in enumerate(eu_4326.itertuples(), start=1):\n",
    "    # grid 611 condition (in order to not process everything)\n",
    "    if i+1 == 611:\n",
    "        geometry = shapely_to_ee_polygon(row.geometry)\n",
    "        dataset = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                   .filterDate('2018-03-01', '2018-09-30')\n",
    "                   .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
    "                   .filterBounds(geometry)\n",
    "                   .map(maskS2CloudsUsingSCL)\n",
    "                   .map(addNDVI))\n",
    "    \n",
    "        if dataset.size().getInfo() == 0:\n",
    "            print(f\"No images found for index {i}, skipping...\")\n",
    "            continue\n",
    "    \n",
    "        firstQuartileComposite = firstQuartile(dataset)\n",
    "        medianFiltered = firstQuartileComposite.focal_median(1000, 'circle', 'meters')\n",
    "        filledComposite = firstQuartileComposite.unmask(medianFiltered).select(['NDVI_p25'])\n",
    "    \n",
    "        exportParams = {\n",
    "            'image': filledComposite,\n",
    "            'description': f\"NDVI_10m_{i}\",\n",
    "            'bucket': 'cog-bucket-test',    # your bucket name\n",
    "            'fileNamePrefix': f\"eu_ndvi/NDVI_10m_{i}\",\n",
    "            'scale': 10,\n",
    "            'region': geometry,\n",
    "            'crs': 'EPSG:3035',\n",
    "            'fileFormat': 'GeoTIFF',\n",
    "            'formatOptions': {'cloudOptimized': True},\n",
    "            'maxPixels': 1e13\n",
    "        }\n",
    "        \n",
    "        task = ee.batch.Export.image.toCloudStorage(**exportParams)\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3064bc3a-4799-46e2-97a5-35f451cefa32",
   "metadata": {},
   "source": [
    "You can monitor the progress on your associated account at https://code.earthengine.google.com/. Once the images are completed processing and stored on your googlecloud, you can move to the next part of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c164cf0-3bd8-44f6-9239-7014aeec30ff",
   "metadata": {},
   "source": [
    "### calculate NDVI for 100mx100m grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1772d9-d90e-427c-9b78-af4e4effec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the environment variable for Google Cloud credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your/credentials.json'\n",
    "\n",
    "# list to hold the paths of the parquet files\n",
    "grids_list = []\n",
    "for parquet_file in glob.glob('data/*.parquet'):\n",
    "    grids_list.append(parquet_file)\n",
    "\n",
    "# # configure logging (recommended if you monitor processing over a lot of files)\n",
    "# log_path = 'logs/green_spaces.log'\n",
    "\n",
    "# # ensure log directory exists\n",
    "# log_dir = os.path.dirname(log_path)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "    \n",
    "# logging.basicConfig(filename=log_path, level=logging.INFO,\n",
    "#                     format='%(asctime)s:%(levelname)s:%(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679cc5f-2256-4ad2-a796-c123c0973556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndvi_row(row, src):\n",
    "    \"\"\"\n",
    "    Calculate the NDVI mean for a single row (geometry) of a GeoDataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A single row from GeoDataFrame.\n",
    "    - src: Raster source object to read data from.\n",
    "\n",
    "    Returns:\n",
    "    - float: The mean NDVI value for the geometry in the row.\n",
    "    \"\"\"\n",
    "    window = from_bounds(*row.geometry.bounds, transform=src.transform)\n",
    "    data = src.read(window=window)\n",
    "    img = data[0]\n",
    "    return np.nanmean(img)\n",
    "\n",
    "def process_grid(grid_path):\n",
    "    \"\"\"\n",
    "    Process each grid to calculate NDVI and save the results back to a parquet file.\n",
    "\n",
    "    Parameters:\n",
    "    - grid_path: The file path to the grid parquet file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grid_number = grid_path.split('_')[-1].split('.')[0]\n",
    "        grid_gdf = gpd.read_parquet(grid_path)\n",
    "\n",
    "        if 'ndvi' in grid_gdf.columns:\n",
    "            logging.info(f'Skipping grid {grid_number} as NDVI already calculated')\n",
    "            return\n",
    "\n",
    "        cog_path = f'gs://cog-bucket-test/eu_ndvi/NDVI_10m_{grid_number}.tif'\n",
    "        # logging.info(f'Started processing grid {grid_number} and {cog_path}')\n",
    "        print(f'Started processing grid {grid_number} and {cog_path}')\n",
    "        \n",
    "        with rasterio.open(cog_path) as src:\n",
    "            if grid_gdf.crs != src.crs:\n",
    "                grid_gdf = grid_gdf.to_crs(src.crs)\n",
    "\n",
    "            calculate_with_src = partial(calculate_ndvi_row, src=src)\n",
    "            grid_gdf['ndvi'] = grid_gdf.apply(lambda row: calculate_with_src(row), axis=1)\n",
    "\n",
    "        grid_gdf.to_parquet(grid_path)\n",
    "        # logging.info(f'Successfully processed grid {grid_path}')\n",
    "        print(f'Successfully processed grid {grid_path}')\n",
    "    except Exception as e:\n",
    "        # logging.error(f'Error processing grid {grid_path}: {e}')\n",
    "        print(f'Error processing grid {grid_path}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9048db6-186e-43b3-865b-c526203f8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "for elem in grids_list:\n",
    "    process_grid(elem)\n",
    "\n",
    "# # configure the number of parallel processes\n",
    "# num_processes = 10 \n",
    "\n",
    "# # create a pool of workers to process grids in parallel\n",
    "# with Pool(processes=num_processes) as pool:\n",
    "#     pool.map(process_grid, grids_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
