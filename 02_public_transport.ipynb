{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fb7207-ad86-4206-a21c-a4bcfd0184ee",
   "metadata": {},
   "source": [
    "This notebook contains code on collecting public transport data from OSM for the generated grids and then calculating the number of public transport options for each 100m x 100m grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f2b8e-bca0-4ac8-984f-4902909d14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "import overpass\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4a3c0-6d44-4b58-89a9-8ef574f6bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for grid files\n",
    "# you might have grids generated here from the 'generate_grids.ipynb'\n",
    "grid_path = 'data/*.parquet'\n",
    "\n",
    "# create a list of all parquet grid files from the specified directory\n",
    "grids_list = [parquet for parquet in glob.glob(grid_path)]\n",
    "print(grids_list)\n",
    "\n",
    "# # configure logging (recommended if you monitor processing over a lot of files)\n",
    "# log_path = 'logs/public_transport.log'\n",
    "\n",
    "# # ensure log directory exists\n",
    "# log_dir = os.path.dirname(log_path)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "    \n",
    "# logging.basicConfig(filename=log_path, level=logging.INFO,\n",
    "#                     format='%(asctime)s:%(levelname)s:%(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1e597-2e63-4377-8478-fc239d19b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_to_overpass_poly(bounds):\n",
    "    \"\"\"\n",
    "    Converts geographic boundaries to an Overpass API polygon string.\n",
    "    \n",
    "    Args:\n",
    "    - bounds (tuple): A tuple containing the minx, miny, maxx, maxy of the bounding box.\n",
    "\n",
    "    Returns:\n",
    "    - str: Polygon string formatted for Overpass API queries.\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    coords = [(miny, minx), (miny, maxx), (maxy, maxx), (maxy, minx), (miny, minx)]\n",
    "    formatted_coords = ' '.join([f'{lon} {lat}' for lon, lat in coords])\n",
    "    return f'poly:\"{formatted_coords}\"'\n",
    "\n",
    "def query_osm_transportation(polygon_wkt):\n",
    "    \"\"\"\n",
    "    Queries Overpass API for public transportation nodes within a given polygon.\n",
    "    \n",
    "    Args:\n",
    "    - polygon_wkt (str): WKT polygon string for the geographic area.\n",
    "\n",
    "    Returns:\n",
    "    - dict: GeoJSON formatted result of the query.\n",
    "    \"\"\"\n",
    "    api = overpass.API(timeout=600)\n",
    "    query = f\"\"\"\n",
    "        (\n",
    "            node[\"highway\" = \"bus_stop\"][\"name\"]({polygon_wkt});\n",
    "            node[\"public_transport\" = \"station\"][\"name\"]({polygon_wkt});\n",
    "            node[\"public_transport\" = \"platform\"][\"name\"]({polygon_wkt});\n",
    "            node[\"tram\"][\"name\"]({polygon_wkt});\n",
    "            node[\"metro\"][\"name\"]({polygon_wkt});\n",
    "        );\n",
    "    \"\"\"\n",
    "    return api.get(query, verbosity='geom')\n",
    "\n",
    "def process_grid(grid_path):\n",
    "    \"\"\"\n",
    "    Processes each grid file to query and save public transport data.\n",
    "    \n",
    "    Args:\n",
    "    - grid_path (str): Path to the grid file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grid_number = grid_path.split('_')[-1].split('.')[0]\n",
    "        output_dir = os.path.join(os.path.dirname(grid_path), 'public_transport_data')\n",
    "        output_file = f'public_transport_points_{grid_number}.parquet'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(os.path.join(output_dir, output_file)):\n",
    "            # logging.info(f'Skipping {output_file} as it already exists')\n",
    "            print(f'Skipping {output_file} as it already exists')\n",
    "            return\n",
    "\n",
    "        grid_gdf = gpd.read_parquet(grid_path)\n",
    "        if 'index' not in grid_gdf.columns:\n",
    "            grid_gdf.reset_index(inplace=True)\n",
    "\n",
    "        grid_gdf_4326 = grid_gdf.to_crs('epsg:4326')\n",
    "        bounds = grid_gdf_4326.total_bounds\n",
    "        polygon_wkt = geo_to_overpass_poly(bounds)\n",
    "        data = query_osm_transportation(polygon_wkt)\n",
    "        data_gdf = gpd.GeoDataFrame.from_features(data)\n",
    "\n",
    "        if data_gdf.empty:\n",
    "            # logging.info(f'No public transport data found for grid {grid_path}')\n",
    "            print(f'No public transport data found for grid {grid_path}')\n",
    "            return\n",
    "\n",
    "        data_gdf.set_crs('epsg:4326', inplace=True)\n",
    "        data_gdf.to_crs(grid_gdf.crs, inplace=True)\n",
    "        data_gdf.to_parquet(os.path.join(output_dir, output_file))\n",
    "        # logging.info(f'Saved public transport data to {output_file}')\n",
    "        print(f'Saved public transport data to {output_file}')\n",
    "\n",
    "        joined = gpd.sjoin(grid_gdf, data_gdf, how=\"left\", predicate='intersects')\n",
    "        node_counts_per_grid = joined.groupby('index')['index_right'].nunique().reset_index(name='pub_trans_count')\n",
    "        grid_gdf_f = grid_gdf.merge(node_counts_per_grid, on='index', how='left')\n",
    "        grid_gdf_f.to_parquet(grid_path)\n",
    "        # logging.info(f'Successfully processed grid {grid_path}')\n",
    "        print(f'Successfully processed grid {grid_path}')\n",
    "\n",
    "    except Exception as e:\n",
    "        # logging.error(f'Error processing grid {grid_path}: {e}')\n",
    "        print(f'Error processing grid {grid_path}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5bf1f-3266-4bc1-841c-3fe38503667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each grid file and log the process\n",
    "for i, grid in enumerate(grids_list):\n",
    "    process_grid(grid)\n",
    "    print(f'Processed grid {i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
