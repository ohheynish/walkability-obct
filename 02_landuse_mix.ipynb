{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bbd68f-807c-469e-b231-437a788f3136",
   "metadata": {},
   "source": [
    "This notebook contains code on collecting land use data from Copernicus LULC dataset for the generated grids and then calculating the entropy value (mix of land use) for each 100m x 100m grid. The developed code relies on google earth engine for processing and google cloud for intermediate storage of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0cc15-83ba-4c3f-84ff-722e049ad97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from multiprocess import Pool\n",
    "import glob\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e361d-6dff-4b59-b161-d83c9d2cbbcb",
   "metadata": {},
   "source": [
    "### data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4359a06-3d26-44ea-924e-b48399327d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set relative path for grid files\n",
    "grid_path = 'data/*.parquet'\n",
    "\n",
    "# create a list of all parquet grid files from the specified directory\n",
    "grids_list = [parquet for parquet in glob.glob(grid_path)]\n",
    "\n",
    "# authenticate and Initialize Google Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c8228-c05c-4208-bd28-29f28c5f8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access Copernicus LULC data\n",
    "lc_dataset = ee.Image('COPERNICUS/CORINE/V20/100m/2018')\n",
    "lc_img = lc_dataset.select('landcover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff8544-66f3-4432-861f-1e120fd52c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap land cover categories into simplified classes and mask out zeroes\n",
    "mask = lc_img.remap(\n",
    "    [111, 112, 121, 122, 123, 124, 141, 142, 211, 212, 213, 221, 222, 223, 231, 241, 242, 243, 244, 311, 312, 313, 321, 322, 323, 324, 333, 511, 512],\n",
    "    [1, 1, 2, 2, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
    "    0)\n",
    "masked_lc_img = mask.updateMask(mask.neq(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60975bc1-6a64-44a4-b9b3-a24c794c1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate entropy with different kernel sizes\n",
    "entropy_5 = masked_lc_img.entropy(ee.Kernel.square(radius=5))\n",
    "entropy_10 = masked_lc_img.entropy(ee.Kernel.square(radius=10))\n",
    "entropy_15 = masked_lc_img.entropy(ee.Kernel.square(radius=15))\n",
    "\n",
    "entropy_imgs = [entropy_5, entropy_10, entropy_15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30305ced-fb2d-4753-b843-180fbee92e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_entropy(grid_path, img, radius):\n",
    "    grid_number = grid_path.split('_')[-1].split('.')[0]\n",
    "    img_name = f'ent_100m_{grid_number}_{radius}.tif'\n",
    "\n",
    "    grid_data = gpd.read_parquet(grid_path)\n",
    "    extent = grid_data.to_crs('epsg:4326').total_bounds\n",
    "\n",
    "    ee_bounds = ee.Geometry.Polygon([\n",
    "        [[extent[0], extent[1]], [extent[0], extent[3]], [extent[2], extent[3]], [extent[2], extent[1]]]\n",
    "    ])\n",
    "\n",
    "    export_params = {\n",
    "        'image': img,\n",
    "        'bucket': 'cog-bucket-test',\n",
    "        'description': f'ent_100m_{grid_number}_{radius}',\n",
    "        'fileNamePrefix': f'ent_100m_{grid_number}_{radius}',\n",
    "        'scale': 100,\n",
    "        'region': ee_bounds.getInfo()['coordinates'],\n",
    "        'crs': 'EPSG:3035',\n",
    "        'fileFormat': 'GeoTIFF',\n",
    "        'formatOptions': {'cloudOptimized': True},\n",
    "        'maxPixels': 1e12,\n",
    "    }\n",
    "\n",
    "    task = ee.batch.Export.image.toCloudStorage(**export_params)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbd0fc-565c-4769-8b87-8ae691f0dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "for i, img in enumerate(entropy_imgs):\n",
    "    radius = '5' if i == 0 else '10' if i == 1 else '15'\n",
    "    for grid_path in grids_list:\n",
    "        export_entropy(grid_path, img, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54269c5b-7f13-41e4-a4c0-c1fbada099f9",
   "metadata": {},
   "source": [
    "### calculate land use mix for 100m x 100m grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122bfa8b-efd3-4054-bb04-a31dba2e7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the environment variable for Google Cloud credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your/credentials.json'\n",
    "\n",
    "# list to hold the paths of the parquet files\n",
    "grids_list = []\n",
    "for parquet_file in glob.glob('data/*.parquet'):\n",
    "    grids_list.append(parquet_file)\n",
    "\n",
    "# # configure logging (recommended if you monitor processing over a lot of files)\n",
    "# log_path = 'logs/slope.log'\n",
    "\n",
    "# # ensure log directory exists\n",
    "# log_dir = os.path.dirname(log_path)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "    \n",
    "# logging.basicConfig(filename=log_path, level=logging.INFO,\n",
    "#                     format='%(asctime)s:%(levelname)s:%(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1550b3-b040-41d8-a7cd-b80e04ddd78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ent_row(row, src):\n",
    "    \"\"\"\n",
    "    Calculate the entropy for a single row (geometry) from a GeoDataFrame using a given raster source.\n",
    "    \n",
    "    Args:\n",
    "    - row (GeoSeries): A GeoDataFrame row representing a polygon.\n",
    "    - src (rasterio.io.DatasetReader): Open raster source to read data from.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Entropy value from the raster.\n",
    "    \"\"\"\n",
    "    left, bottom, right, top = row.geometry.bounds\n",
    "    window = from_bounds(left, bottom, right, top, src.transform)\n",
    "    data = src.read(window=window)\n",
    "    img = data[0]\n",
    "\n",
    "    if img.shape != (1, 1):\n",
    "        logging.info(f'More than one pixel in the window')\n",
    "        return None  # Consider returning NaN or another value as appropriate\n",
    "    return img[0, 0]\n",
    "\n",
    "def process_grid(grid_path, radius):\n",
    "    \"\"\"\n",
    "    Process a single grid file to calculate and update entropy data.\n",
    "    \n",
    "    Args:\n",
    "    - grid_path (str): Path to the grid file.\n",
    "    - radius (str): The radius parameter for which entropy was calculated.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grid_number = grid_path.split('_')[-1].split('.')[0]\n",
    "        grid_gdf = gpd.read_parquet(grid_path)\n",
    "\n",
    "        if f'ent_{radius}' in grid_gdf.columns:\n",
    "            logging.info(f'Skipping grid {grid_number} for radius {radius} as entropy already calculated')\n",
    "            return\n",
    "\n",
    "        cog_path = f'./eurostat_grid/grids_100/entropy_data/entropy_{radius}/ent_100m_{grid_number}_{radius}.tif'\n",
    "        logging.info(f'Started processing grid {grid_number} with {cog_path}')\n",
    "\n",
    "        with rasterio.open(cog_path) as src:\n",
    "            if grid_gdf.crs != src.crs:\n",
    "                grid_gdf = grid_gdf.to_crs(src.crs)\n",
    "            calculate_with_src = partial(calculate_ent_row, src=src)\n",
    "            grid_gdf[f'ent_{radius}'] = grid_gdf.apply(lambda row: calculate_with_src(row), axis=1)\n",
    "\n",
    "        grid_gdf.to_parquet(grid_path)\n",
    "        logging.info(f'Successfully processed grid {grid_path} for {radius} radius')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error processing grid {grid_path} for {radius} radius: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b086779-9c30-41fa-8d1a-8df8ea71cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the radii to process\n",
    "radii = ['5', '10', '15']\n",
    "\n",
    "# sequential\n",
    "for elem in grids_list:\n",
    "    for radius in radii:\n",
    "        process_grid(elem, radius)\n",
    "        \n",
    "# # parallel\n",
    "# for radius in radii:\n",
    "#     num_processes = 7\n",
    "#     process_with_radius = partial(process_grid, radius=radius)\n",
    "#     with Pool(processes=num_processes) as pool:\n",
    "#         pool.map(process_with_radius, grids_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
