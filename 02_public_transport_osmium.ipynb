{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fb7207-ad86-4206-a21c-a4bcfd0184ee",
   "metadata": {},
   "source": [
    "This notebook contains code on collecting public transport data from OSM for the generated grids and then calculating the number of public transport options for each 100m x 100m grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f2b8e-bca0-4ac8-984f-4902909d14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import osmium\n",
    "import shapely.geometry\n",
    "from shapely.geometry import box\n",
    "import subprocess\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4a3c0-6d44-4b58-89a9-8ef574f6bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for grid files\n",
    "# you might have grids generated here from the 'generate_grids.ipynb'\n",
    "grid_path = 'data/*.parquet'\n",
    "\n",
    "# create a list of all parquet grid files from the specified directory\n",
    "grids_list = [parquet for parquet in glob.glob(grid_path)]\n",
    "print(grids_list)\n",
    "\n",
    "# # configure logging (recommended if you monitor processing over a lot of files)\n",
    "# log_path = 'logs/public_transport.log'\n",
    "\n",
    "# # ensure log directory exists\n",
    "# log_dir = os.path.dirname(log_path)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "    \n",
    "# logging.basicConfig(filename=log_path, level=logging.INFO,\n",
    "#                     format='%(asctime)s:%(levelname)s:%(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284f5b4-6429-49a5-a234-2b8d52a8e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_public_transport_node(tags):\n",
    "    \"\"\"\n",
    "    Determine if a node has public transport-related tags.\n",
    "    \"\"\"\n",
    "    transport_tags = {\n",
    "        (\"highway\", \"bus_stop\"),\n",
    "        (\"public_transport\", \"station\"),\n",
    "        (\"public_transport\", \"platform\"),\n",
    "        (\"railway\", \"station\"),\n",
    "        (\"railway\", \"tram_stop\"),\n",
    "        (\"railway\", \"halt\"),\n",
    "        (\"railway\", \"subway_entrance\"),\n",
    "        (\"amenity\", \"bus_station\"),\n",
    "    }\n",
    "    return any(tags.get(k) == v for k, v in transport_tags)\n",
    "\n",
    "def extract_transport_nodes_from_pbf(pbf_path):\n",
    "    \"\"\"\n",
    "    Extract public transportation nodes from an OSM PBF file.\n",
    "\n",
    "    Args:\n",
    "    - pbf_path (str): Path to the .osm.pbf file.\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame of transport nodes.\n",
    "    \"\"\"\n",
    "    transport_nodes = []\n",
    "\n",
    "    class Handler(osmium.SimpleHandler):\n",
    "        def node(self, n):\n",
    "            if n.location.valid() and is_public_transport_node(n.tags):\n",
    "                transport_nodes.append({\n",
    "                    \"id\": n.id,\n",
    "                    \"name\": n.tags.get(\"name\"),\n",
    "                    \"geometry\": shapely.geometry.Point(n.location.lon, n.location.lat),\n",
    "                    \"type\": next((f\"{k}={v}\" for k, v in n.tags if (k, v) in {\n",
    "                        (\"highway\", \"bus_stop\"),\n",
    "                        (\"public_transport\", \"station\"),\n",
    "                        (\"public_transport\", \"platform\"),\n",
    "                        (\"railway\", \"station\"),\n",
    "                        (\"railway\", \"tram_stop\"),\n",
    "                        (\"railway\", \"halt\"),\n",
    "                        (\"railway\", \"subway_entrance\"),\n",
    "                        (\"amenity\", \"bus_station\"),\n",
    "                    }), None)\n",
    "                })\n",
    "\n",
    "    handler = Handler()\n",
    "    handler.apply_file(pbf_path, locations=True)\n",
    "\n",
    "    if not transport_nodes:\n",
    "        return gpd.GeoDataFrame(columns=[\"id\", \"name\", \"type\", \"geometry\"], geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "    return gpd.GeoDataFrame(transport_nodes, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1e597-2e63-4377-8478-fc239d19b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_grid(grid_path):\n",
    "    \"\"\"\n",
    "    Processes each grid file to query and save public transport data.\n",
    "    \n",
    "    Args:\n",
    "    - grid_path (str): Path to the grid file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grid_number = grid_path.split('_')[-1].split('.')[0]\n",
    "        output_dir = os.path.join(os.path.dirname(grid_path), 'public_transport_data')\n",
    "        output_file = f'public_transport_points_{grid_number}.parquet'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(os.path.join(output_dir, output_file)):\n",
    "            # logging.info(f'Skipping {output_file} as it already exists')\n",
    "            print(f'Skipping {output_file} as it already exists')\n",
    "            return\n",
    "\n",
    "        grid_gdf = gpd.read_parquet(grid_path)\n",
    "        if 'index' not in grid_gdf.columns:\n",
    "            grid_gdf.reset_index(inplace=True)\n",
    "\n",
    "        grid_gdf_4326 = grid_gdf.to_crs('epsg:4326')\n",
    "        bounds = grid_gdf_4326.total_bounds\n",
    "        buffered_box = box(*bounds).buffer(0.01)\n",
    "        # logging.info(f'Started processing grid {grid_number}')\n",
    "        print(f'Started processing grid {grid_number}')\n",
    "\n",
    "        # clip .pbf file\n",
    "        clipped_pbf_path = f'data/{grid_number}.pbf'\n",
    "        os.makedirs(os.path.dirname(clipped_pbf_path), exist_ok=True)\n",
    "\n",
    "        bbox_str = ','.join(map(str, buffered_box.bounds))\n",
    "        subprocess.run([\n",
    "            'osmium', 'extract',\n",
    "            '-b', bbox_str,\n",
    "            '/Volumes/ssd1/osm_europe/europe-latest.osm.pbf',\n",
    "            '-o', clipped_pbf_path,\n",
    "            '--overwrite'\n",
    "        ], check=True)\n",
    "        print(f'clipped PBF for {grid_number}')\n",
    "\n",
    "        # process with pyosmium\n",
    "        data_gdf = extract_transport_nodes_from_pbf(clipped_pbf_path)\n",
    "        \n",
    "        if data_gdf.empty:\n",
    "            # logging.info(f'No public transport data found for grid {grid_path}')\n",
    "            print(f'No public transport data found for grid {grid_path}')\n",
    "            return\n",
    "\n",
    "        data_gdf.to_crs(grid_gdf.crs, inplace=True)\n",
    "        data_gdf.to_parquet(os.path.join(output_dir, output_file))\n",
    "        # logging.info(f'Saved public transport data to {output_file}')\n",
    "        print(f'Saved public transport data to {output_file}')\n",
    "\n",
    "        joined = gpd.sjoin(grid_gdf, data_gdf, how=\"left\", predicate='intersects')\n",
    "        node_counts_per_grid = joined.groupby('index')['index_right'].nunique().reset_index(name='pub_trans_count')\n",
    "        grid_gdf_f = grid_gdf.merge(node_counts_per_grid, on='index', how='left').fillna({'pub_trans_count': 0})\n",
    "        grid_gdf_f.to_parquet(grid_path)\n",
    "        # logging.info(f'Successfully processed grid {grid_path}')\n",
    "        print(f'Successfully processed grid {grid_path}')\n",
    "\n",
    "        # clean up temp PBF file\n",
    "        if os.path.exists(clipped_pbf_path):\n",
    "            os.remove(clipped_pbf_path)\n",
    "            \n",
    "        del data_gdf, grid_gdf, grid_gdf_f\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        # logging.error(f'Error processing grid {grid_path}: {e}')\n",
    "        print(f'Error processing grid {grid_path}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5bf1f-3266-4bc1-841c-3fe38503667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "for elem in grids_list:\n",
    "    process_grid(elem)\n",
    "\n",
    "# # parallel processsing if you want to process a lot of files\n",
    "# num_processes = 5\n",
    "\n",
    "# with Pool(processes=num_processes) as pool:\n",
    "#     pool.map(process_grid, grids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5b840-a3d0-4dc6-b3da-561915e285fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
