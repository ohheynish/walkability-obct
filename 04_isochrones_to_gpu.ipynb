{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61258c0-418b-4b7c-86c1-e7ada07a2377",
   "metadata": {},
   "source": [
    "This notebook contains code on how to convert the isochrone polygons (and other component data) to arrays, which can be then processed parallely on GPU for stuff like weighted distance decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae10bc-7c0f-4636-ac01-1cfb658710a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geocube.api.core import make_geocube\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "from multiprocess import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a4ffe6-61d9-4187-989c-2e84ca5b3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for grid files\n",
    "# you might have grids generated here from the 'generate_grids.ipynb'\n",
    "grid_path = 'data/*.parquet'\n",
    "\n",
    "# create a list of all parquet grid files from the specified directory\n",
    "grids_list = [parquet for parquet in glob.glob(grid_path)]\n",
    "print(grids_list)\n",
    "\n",
    "# # configure logging (recommended if you monitor processing over a lot of files)\n",
    "# log_path = 'logs/isochrones_to_gpu.log'\n",
    "\n",
    "# # ensure log directory exists\n",
    "# log_dir = os.path.dirname(log_path)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "    \n",
    "# logging.basicConfig(filename=log_path, level=logging.INFO,\n",
    "#                     format='%(asctime)s:%(levelname)s:%(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d99b7-b341-482e-91a4-82f23749d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(grid_gdf):\n",
    "    \"\"\"\n",
    "    Find neighbors of a grid cell by buffering its boundaries and identifying intersecting grids.\n",
    "    \n",
    "    Args:\n",
    "    - grid_gdf (GeoDataFrame): GeoDataFrame of the grid to find neighbors for.\n",
    "    \n",
    "    Returns:\n",
    "    - List[GeoDataFrame]: List of GeoDataFrames of the neighboring grid cells.\n",
    "    \"\"\"\n",
    "    grid_id = grid_gdf['grid_100000_id'].unique()\n",
    "    buffer = grid_gdf.unary_union.buffer(3000, cap_style=3)\n",
    "    potential_neighbors = grid_100km[grid_100km.intersects(buffer)]\n",
    "    \n",
    "    nbr_gdfs = []\n",
    "    for neighbor_id in set(potential_neighbors.index) - set(grid_id):\n",
    "        nbr_path = f'data/grids_100_{neighbor_id}.parquet'\n",
    "        temp_nbr_gdf = gpd.read_parquet(nbr_path)\n",
    "        temp_nbr_gdf = temp_nbr_gdf[temp_nbr_gdf.intersects(buffer)]\n",
    "        nbr_gdfs.append(temp_nbr_gdf)\n",
    "    \n",
    "    return nbr_gdfs\n",
    "\n",
    "def rasterize_geodf(geodf, columns, resolution):\n",
    "    \"\"\"\n",
    "    Rasterizes specified columns of a GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - geodf (GeoDataFrame): GeoDataFrame to rasterize.\n",
    "    - columns (List[str]): List of column names to rasterize.\n",
    "    - resolution (tuple): The pixel resolution in the form of (width, height).\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple: A tuple containing the rasterized data array, transform, and CRS.\n",
    "    \"\"\"\n",
    "    cube = make_geocube(vector_data=geodf, measurements=columns, resolution=resolution, output_crs=\"EPSG:3035\")\n",
    "    bands = [cube[col].values for col in columns]\n",
    "    return np.stack(bands), cube.rio.transform(), cube.rio.crs\n",
    "\n",
    "def process_grid(grid_path):\n",
    "    \"\"\"\n",
    "    Process each grid to find neighbors, merge data, and create a raster image for GPU processing.\n",
    "    \n",
    "    Args:\n",
    "    - grid_path (str): Path to the grid file.\n",
    "    \"\"\"\n",
    "    grid_gdf = gpd.read_parquet(grid_path)\n",
    "    grid_num = grid_gdf['grid_100000_id'].unique()[0]\n",
    "    \n",
    "    output_dir = 'data/iso_for_gpu'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = f'img_{grid_num}.tif'\n",
    "    \n",
    "    if os.path.exists(os.path.join(output_dir, output_file)):\n",
    "        print(f'Skipping grid {grid_num} as iso_gpu already calculated')\n",
    "        return\n",
    "    \n",
    "    nbr_gdfs = find_neighbors(grid_gdf=grid_gdf)\n",
    "    new_grid_gdf = gpd.GeoDataFrame(pd.concat([grid_gdf] + nbr_gdfs, ignore_index=True))\n",
    "    \n",
    "    iso_path = f'data/isochrones/isochrones_{grid_num}.parquet'\n",
    "    iso_gdf = gpd.read_parquet(iso_path)\n",
    "    \n",
    "    joined_gdf = iso_gdf.sjoin(new_grid_gdf, how='left', predicate='intersects')\n",
    "    joined_gdf.drop(columns=['index_right'], inplace=True)\n",
    "    \n",
    "    columns = ['street_walk_length', 'num_street_intersections', 'ndvi', 'ent_5',\n",
    "               'slope', 'population', 'pub_trans_count', 'index']\n",
    "    raster_data, transform, crs = rasterize_geodf(new_grid_gdf, columns, resolution=(-100, 100))\n",
    "    \n",
    "    # Saving raster data\n",
    "    with rasterio.open(os.path.join(output_dir, output_file), 'w', driver='GTiff',\n",
    "                       height=raster_data.shape[1], width=raster_data.shape[2],\n",
    "                       count=len(columns), dtype=raster_data.dtype,\n",
    "                       crs=crs, transform=transform) as dst:\n",
    "        for i in range(len(columns)):\n",
    "            dst.write(raster_data[i], i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe61f41-4029-4918-b8f2-861720b32145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "for elem in grids_list:\n",
    "    process_grid(elem)\n",
    "\n",
    "# # parallel\n",
    "# num_processes = 5\n",
    "\n",
    "# with Pool(processes=num_processes) as pool:\n",
    "#     pool.map(process_grid, grids_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
